Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy3', 'environment': <environment.Environment object at 0x00000221ABCBFFD0>, 'variant': 0, 'input_shape': 21, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 10, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 193.85499572753906
Best testing score of 301.00 achieved in episode 55
Actions taken during best testing episode: [0, 4, 2, 2, 1, 2, 4, 4, 4, 3, 3, 3, 1, 1, 3, 3, 1, 1, 0, 2, 2, 4, 4, 2, 1, 1, 3, 4, 3, 4, 0, 0, 4, 2, 3, 4, 1, 2, 2, 1, 4, 4, 3, 2, 2, 4, 4, 0, 0, 0, 4, 4, 2, 2, 1, 4, 3, 4, 2, 4, 2, 2, 1, 4, 3, 4, 2, 1, 4, 3, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 1, 4, 2, 2, 1, 3, 4, 4, 3, 4, 0, 0, 3, 2, 4, 1, 0, 0, 1, 2, 1, 3, 4, 3, 4, 1, 4, 1, 2, 2, 4, 4, 3, 3, 4, 3, 1, 2, 2, 1, 4, 3, 4, 2, 2, 1, 2, 4, 4, 4, 3, 1, 2, 1, 2, 2, 4, 4, 4, 1, 3, 3, 3, 2, 1, 4, 2, 4, 0, 0, 0, 2, 2, 1, 2, 2, 4, 4, 4, 4, 3, 3, 2, 2, 4, 4, 1, 2, 4, 2, 2, 2, 1, 2, 4, 3, 4, 4, 4, 0, 0, 4, 4, 4, 0, 0, 0, 3, 2, 2, 4, 1, 4, 1, 3, 0, 4, 4]

Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy3', 'environment': <environment.Environment object at 0x000002ADE887FFD0>, 'variant': 0, 'input_shape': 21, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 50, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 202.26499938964844
Best testing score of 311.00 achieved in episode 55
Actions taken during best testing episode: [4, 0, 2, 2, 1, 2, 4, 4, 4, 3, 3, 3, 1, 1, 3, 3, 1, 1, 4, 2, 2, 4, 4, 2, 1, 1, 3, 3, 4, 4, 4, 4, 4, 3, 2, 1, 4, 2, 2, 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 0, 4, 4, 2, 2, 1, 4, 3, 4, 2, 4, 3, 2, 1, 4, 2, 1, 4, 3, 2, 4, 2, 2, 1, 2, 4, 4, 4, 3, 2, 4, 2, 2, 1, 1, 4, 4, 3, 3, 2, 2, 2, 2, 4, 4, 4, 4, 3, 2, 4, 1, 1, 2, 1, 3, 4, 3, 4, 4, 4, 2, 1, 1, 2, 4, 4, 3, 3, 3, 1, 2, 2, 1, 4, 4, 3, 2, 2, 1, 2, 4, 4, 4, 3, 4, 4, 0, 4, 4, 4, 4, 4, 2, 3, 1, 4, 4, 4, 2, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 1, 2, 3, 4, 1, 1, 2, 2, 4, 4, 3, 3, 2, 4, 1, 1, 2, 2, 4, 3, 4, 3, 4, 4, 4, 4, 4, 0, 4, 4, 4, 3, 2, 2, 1, 4, 4, 1, 3, 4, 4, 4]

Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy3', 'environment': <environment.Environment object at 0x000001F727DE3FD0>, 'variant': 2, 'input_shape': 21, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 10, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 213.82000732421875
Best testing score of 375.00 achieved in episode 15
Actions taken during best testing episode: [4, 3, 2, 2, 4, 4, 1, 2, 2, 2, 2, 3, 2, 4, 1, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 4, 3, 0, 4, 2, 2, 1, 1, 1, 2, 4, 3, 3, 3, 4, 4, 1, 4, 4, 3, 2, 4, 1, 4, 4, 3, 2, 3, 4, 1, 1, 1, 1, 3, 3, 3, 2, 2, 4, 4, 1, 4, 4, 4, 4, 4, 1, 1, 3, 3, 4, 4, 2, 2, 3, 3, 1, 1, 2, 3, 2, 2, 1, 3, 4, 4, 4, 1, 3, 2, 4, 1, 4, 4, 2, 4, 2, 4, 2, 2, 0, 0, 2, 0, 3, 2, 3, 2, 4, 1, 4, 1, 3, 2, 3, 1, 4, 1, 1, 1, 3, 3, 3, 3, 2, 2, 3, 4, 1, 4, 1, 1, 1, 3, 3, 3, 2, 2, 4, 4, 1, 4, 4, 2, 3, 2, 1, 2, 4, 4, 1, 3, 2, 4, 1, 3, 0, 0, 0, 1, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 2, 1, 1, 1, 3, 3, 3, 4, 4, 1, 3]
Worst testing score of 101.00 achieved in episode 75
Actions taken during worst testing episode: [4, 4, 2, 2, 2, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 3, 2, 3, 2, 1, 1, 3, 4, 4, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 3, 0, 0, 4, 2, 2, 4, 4, 1, 3, 2, 2, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 3, 2, 1, 3, 2, 0, 2, 1, 2, 4, 4, 1, 1, 0, 4, 1, 4, 3, 1, 0, 4, 1, 1, 4, 0, 0, 0, 0, 0, 2, 2, 0, 0, 4, 1, 0, 3, 3, 3, 2, 2, 4, 4, 1, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 1, 4, 1, 3, 1, 4, 0, 1, 1, 1, 1, 4, 0, 0, 1, 1, 1, 1, 2, 2, 3, 1, 2]

Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy3', 'environment': <environment.Environment object at 0x000001F727DE3FD0>, 'variant': 2, 'input_shape': 21, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 50, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 229.3000030517578
Best testing score of 391.00 achieved in episode 95
Actions taken during best testing episode: [0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 3, 2, 2, 4, 1, 4, 1, 2, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 3, 2, 2, 1, 1, 1, 3, 3, 4, 3, 4, 4, 1, 3, 2, 2, 4, 4, 1, 3, 2, 3, 2, 4, 1, 4, 1, 1, 3, 3, 2, 2, 1, 3, 4, 4, 1, 3, 3, 1, 1, 3, 3, 2, 2, 4, 4, 1, 1, 3, 1, 3, 2, 2, 4, 4, 1, 3, 2, 3, 4, 1, 1, 3, 2, 3, 1, 4, 1, 3, 2, 2, 4, 4, 1, 0, 4, 3, 0, 2, 2, 1, 1, 1, 3, 3, 3, 4, 4, 1, 3, 2, 3, 2, 4, 4, 1, 1, 3, 1, 4, 0, 0, 0, 0, 3, 1, 3, 2, 2, 1, 3, 4, 4, 1, 3, 3, 2, 1, 4, 1, 3, 2, 2, 1, 3, 4, 4, 1, 3, 2, 2, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4]
Worst testing score of 108.00 achieved in episode 75
Actions taken during worst testing episode: [0, 0, 0, 2, 4, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 3, 3, 2, 2, 4, 4, 1, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 4, 0, 3, 2, 2, 1, 3, 4, 4, 1, 3, 2, 3, 2, 1, 4, 4, 1, 4, 0, 0, 2, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 2, 0, 2, 0, 4, 0, 4, 0, 3, 2, 2, 4, 4, 1, 0, 0, 2, 4, 0, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 0, 2, 2, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 2, 4, 4, 3, 4, 4, 4, 3, 3, 1, 4, 0, 4, 4, 0, 0, 0, 4, 1, 4, 4, 4, 4, 0, 3, 2, 2]

Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy3', 'environment': <environment.Environment object at 0x000001F727DE3FD0>, 'variant': 2, 'input_shape': 21, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 100, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 233.01499938964844
Best testing score of 381.00 achieved in episode 50
Actions taken during best testing episode: [0, 3, 2, 2, 3, 4, 4, 1, 1, 3, 2, 2, 1, 3, 4, 4, 1, 0, 3, 2, 3, 1, 4, 1, 3, 2, 4, 1, 3, 2, 3, 1, 4, 1, 3, 2, 2, 4, 4, 1, 3, 2, 2, 1, 1, 1, 3, 3, 3, 4, 4, 1, 0, 0, 0, 4, 0, 0, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 4, 3, 2, 2, 1, 3, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 2, 2, 4, 4, 1, 1, 0, 3, 2, 4, 1, 3, 3, 3, 3, 2, 2, 4, 1, 4, 1, 3, 3, 1, 1, 3, 2, 3, 4, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 3, 3, 0, 0, 0, 3, 2, 2, 3, 4, 4, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 4, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 0, 0, 0, 0, 3, 2, 2, 1, 3, 4, 4, 1, 3, 3, 2, 4, 1, 1, 2, 2, 2, 3, 2, 3, 1, 4, 1, 0]
Worst testing score of 115.00 achieved in episode 75
Actions taken during best testing episode: [0, 4, 0, 0, 4, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 2, 3, 4, 1, 4, 1, 3, 2, 2, 1, 1, 3, 3, 4, 4, 1, 0, 0, 0, 0, 0, 0, 3, 2, 2, 4, 4, 1, 0, 3, 2, 2, 4, 4, 1, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 2, 4, 4, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 3, 2, 2, 1]

Testing PPO with parameters: {'seed': 10, 'observation': 'ImageLike', 'environment': <environment_CNN_moving.Environment object at 0x000001FCCA0C3FD0>, 'variant': 0, 'input_shape': 125, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 10, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 205.59500122070312
Best testing score of 313.50 achieved in episode 55
Actions taken during best testing episode: [4, 4, 3, 1, 2, 2, 2, 3, 4, 4, 4, 3, 3, 1, 1, 3, 3, 1, 1, 2, 2, 4, 4, 2, 1, 1, 3, 3, 4, 0, 0, 4, 4, 3, 2, 1, 4, 2, 1, 2, 4, 3, 4, 2, 2, 4, 4, 4, 4, 0, 0, 0, 2, 1, 2, 3, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 1, 2, 3, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 1, 1, 2, 2, 3, 3, 4, 4, 0, 0, 3, 2, 1, 4, 0, 2, 1, 1, 3, 4, 3, 0, 4, 0, 0, 1, 1, 2, 2, 3, 4, 3, 4, 3, 1, 1, 2, 2, 2, 4, 4, 4, 3, 1, 2, 4, 3, 4, 0, 4, 0, 4, 4, 0, 2, 2, 2, 2, 3, 4, 4, 4, 1, 4, 2, 4, 3, 1, 4, 4, 4, 4, 2, 4, 2, 1, 4, 3, 1, 1, 2, 2, 3, 3, 4, 4, 2, 4, 2, 3, 2, 4, 1, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 4, 1, 4, 4, 1, 3, 0, 0, 0]
Worst testing score of 131.00 achieved in episode 12
Actions taken during worst testing episode: [4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 0, 0, 0, 4, 4, 4, 4, 4, 2, 2, 2, 2, 3, 4, 1, 4, 4, 4, 4, 4, 4, 4, 0, 4, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 2, 1, 2, 3, 4, 4, 3, 2, 3, 1, 4, 1, 2, 3, 2, 4, 1, 4, 1, 1, 2, 2, 3, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 3, 1, 4, 1, 4, 2, 2, 2, 3, 1, 4, 4, 4, 2, 2, 2, 3, 1, 1, 4, 1, 4, 3, 4, 3, 3, 2, 2, 3, 2, 2, 2, 2, 4, 4, 3, 3, 3, 3, 4, 1, 4, 1, 3, 1, 2, 0, 0, 0, 0, 3, 2, 4, 1, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 0, 4, 0, 2, 2, 2, 4, 4, 4, 1, 2, 2, 2, 3, 4, 4, 4, 2, 3, 2, 3, 1, 4, 1, 4, 1, 1, 2, 3, 3, 4, 4, 2, 0, 3, 3, 2, 2, 4, 4, 1, 4, 4, 4, 4, 1, 2, 4, 4, 4, 3]

Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy5', 'environment': <environment.Environment object at 0x000002043D543FD0>, 'variant': 0, 'input_shape': 29, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 10, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 201.4949951171875
Best testing score of 324.00 achieved in episode 55
Actions taken during best testing episode: [4, 4, 2, 1, 2, 2, 4, 4, 4, 3, 3, 3, 1, 1, 3, 3, 1, 1, 4, 2, 2, 4, 4, 2, 1, 1, 3, 3, 4, 4, 4, 4, 4, 3, 2, 1, 4, 2, 2, 1, 3, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 1, 2, 4, 3, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 1, 3, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 3, 2, 4, 1, 4, 4, 1, 1, 2, 3, 3, 4, 4, 4, 4, 2, 1, 2, 1, 4, 3, 3, 4, 3, 1, 2, 2, 1, 2, 4, 4, 3, 4, 1, 2, 3, 4, 2, 2, 2, 1, 1, 3, 4, 3, 4, 4, 3, 2, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 3, 4, 2, 2, 2, 3, 4, 1, 4, 4, 2, 4, 2, 3, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 3, 4, 1, 4, 1, 3, 4, 4, 4]
Worst testing score of 128.00 achieved in episode 75
Actions taken during worst testing episode: [4, 4, 0, 2, 2, 1, 2, 3, 4, 4, 4, 4, 2, 0, 2, 1, 1, 4, 3, 3, 4, 1, 1, 2, 2, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 1, 4, 3, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 3, 1, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 2, 1, 1, 3, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 1, 2, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 2, 1, 4, 4, 2, 2, 3, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 3, 4, 1, 4, 1, 2, 2, 1, 3, 4, 4, 3, 3, 4, 1, 1, 2, 2, 3, 3, 1, 1, 4, 4, 4]

Testing PPO with parameters: {'seed': 10, 'observation': 'NGreedy1', 'environment': <environment.Environment object at 0x000002717C223FD0>, 'variant': 0, 'input_shape': 13, 'hidden_size': 256, 'early_stopping': 20, 'validation_after_episodes': 5, 'lr_actor': 0.001, 'lr_critic_1': 0.005, 'lr_critic_2': 0.005, 'return_lambda': 0.875, 'gamma': 0.9, 'clip_epsilon': 0.05, 'episode_steps': 200, 'no_of_actors': 10, 'actor_updates_per_episode': 100, 'critic_updates_per_episode': 100, 'clip_annealing_factor': 0.99}
Mean testing score of 149.19500732421875
Best testing score of 226.00 achieved in episode 55
Actions taken during best testing episode: [4, 4, 2, 2, 1, 2, 4, 4, 4, 3, 1, 1, 2, 2, 3, 4, 3, 4, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 2, 1, 4, 2, 2, 2, 3, 2, 4, 4, 1, 4, 4, 2, 2, 4, 4, 4, 2, 1, 2, 4, 3, 4, 2, 4, 2, 3, 2, 2, 1, 4, 4, 4, 2, 4, 2, 2, 1, 2, 4, 3, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 3, 2, 1, 4, 1, 1, 2, 3, 4, 3, 4, 4, 4, 4, 1, 1, 2, 2, 3, 4, 4, 3, 2, 2, 1, 2, 4, 4, 4, 3, 1, 1, 2, 2, 2, 4, 3, 4, 4, 3, 0, 0, 0, 0, 0, 2, 2, 2, 3, 2, 4, 4, 4, 1, 4, 2, 4, 2, 2, 2, 2, 1, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 2, 1, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 2, 1, 4, 4, 2, 4, 4, 4, 4]
Worst testing score of 70.00 achieved in episode 41
Actions taken during worst testing episode: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 2, 2, 2, 4, 2, 4, 2, 2, 1, 3, 3, 4, 1, 1, 4, 4, 4, 1, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 1, 4, 4, 3, 4, 4, 2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 1, 2, 4, 4, 3, 3, 4, 4, 2, 2, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 1, 1, 2, 3, 3, 4, 4, 4, 4, 0, 0, 0, 0, 3, 2, 3, 2, 2, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 2, 2, 0, 1, 4, 1, 4, 2, 3, 2, 2, 1, 4, 4, 4, 1, 1, 2, 2, 3, 4, 4, 3, 1, 1, 2, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 1, 2, 1, 4, 3, 3, 4, 4, 2]

